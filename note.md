# 概述

## 课程介绍

软件与算法：

- 编程语言
- Caffeine、TensorFlow、Theano等深度学习框架
- OpenCV等计算库

嵌入式硬件实现：

- Verilog实现
- FPGA/ARM 等嵌入式开发环境
- 基本的硬件调试仪器的使用

## 课程内容

### 课程大纲

1. 智能计算加速前沿技术介绍
   1. 智能时代课程教育和人才培养为何必须需要重视“系统能力”
   2. 介绍相关科学技术前沿研究以及产业发展，培养学术研究和技术创新的视野
   3. 为何要针对智能计算任务设计专用的架
2. 智能计算模型与方法
   1. 深度学习、图计算等智能计算的算法模型和原理介绍
   2. 重点介绍深度神经网络计算模型（课程的实践目标在于设计 DNN 加速器）
   3. 介绍 DNN 算法框架、工具、环境等
3. 嵌入式系统加速器设计方法
   1. Zynq FPGA 平台设计开发环境和流程
   2. IP 、总线、接口、 HLS 、时序优化
   3. PS PL 异构加速器设计方法（加速器作为协处理器的设计流程）
4. 算法到硬件的映射与优化方法
   1. 数据流的生成和指令流的映射
   2. 硬件单元的（伪）指令化
   3. 计算单元与数据通路的设计
5. 深度神经网络加速器设计
   1. DNN 加速器的架构设计依据和需求分析
   2. 以 TPU 和 Eyeriss 架构为例进行架构设计
   3. CNN 计算过程的算子化以及数据流生成
6. 加速器的专用集成电路实现方法
   1. CNN 加速器的 FPGA 实现（课程实践）
   2. CNN 加速器的 ASIC 实现需求和区别
   3. ASIC 的设计流程基本介绍
7. 嵌入式深度学习加速器应用前景
   1. DNN 加速器在 CV 等领域的实际应用
   2. 底层架构设计与系统优化之间的关系

### 成绩构成

- 平时作业：30%
- 文献报告：10%
- 课程实验：60%
  - 共6个lab
  - Lab 1 ：神经网络
    - 任务：采用 C/Python 实现一个简单的多层神经网络网络
    - 目的：掌握和理解神经网络的基本原理和计算过程
  - Lab 2 ：深度学习框架
    - 任务：在 Caffe/TensorFlow/ PyTorch 框架上实现 DNN 网络
    - 目的：掌握和理解 DNN 结构和计算流图，并进行简单的调优
  - Lab 3：Zynq FPGA 设计方法
    - 任务：在 Zynq 环境下实现一个矩阵乘加计算模块
    - 目的：掌握开发方法， 包括工具、环境和设计技巧
  - Lab 4：Zynq FPGA 平台的软硬件交互
    - 任务：设计软硬件交互接口，并调用矩阵乘加模块
    - 目的：理解和掌握软硬件交互的逻辑和技巧
  - Lab 5：设计 NaiveTPU 进行矩阵计算加速
    - 任务：在 Zynq 上实现矩阵计算，基于前置实验中的矩阵乘加运算模块以及软硬件交互框架
    - 目的：完成矩阵计算加速的设计与应用，实现基本功能测试
  - Lab 6：设计 NaiveTPU 进行神经网络推理加速
    - 任务：在 Zynq 上实现小型神经网络的计算推理加速
    - 目的：完成神经网络计算加速的实验验证，理解专用硬件设计的加速原理，并进行实验效果的对比分析

## 关于智能计算系统

论文整理：https://github.com/fengbintu/Neural-Networks-on-Silicon

AI芯片整理：https://github.com/basicmi/AI-Chip

学术研究整理：https://github.com/HuaizhengZhang/AI-System-School

# 深度神经网络DNN





































































